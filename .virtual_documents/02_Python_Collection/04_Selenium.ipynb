





#셀레리움 라이브러리 설치
!pip install selenium


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time

options = Options() # 객체!
options # option 은 options의 인스턴스


#특정함수안에서  드라이버 생성시 함수종료될 때 브라우저 같이 종료되는 문제 대응
options.add_experimental_option('detach', True)
#for 문 반복이 끝나도 브라우저가 같이 꺼지는거 방지하는 기능





url = 'https://naver.com'
driver = webdriver.Chrome(options = options)


driver.get(url) # 실행 
time.sleep(2) 





driver.back()


driver.forward()


driver.refresh()





title = driver.title
url = driver.current_url
handle = driver.current_window_handle
print(title, url, handle)
# 각각 탭에 뜨는 이름, url 창에 주소, 윈도우 창에 대한 ID를 의미
#ID가 있다 = 동시에 여러개를 조작할 수 있다





drive.find_element?


driver.find_element(By.ID, 'query')


# 키 입력
driver.find_element(By.ID, 'query').send_keys('뉴진스')


driver.find_element(By.CLASS_NAME, "search_input").send_keys('블랙핑크')


driver.find_element(By.NAME, "query").send_keys('르세라핌')


driver.find_element(By.CSS_SELECTOR, "#query").send_keys('에스파')


driver.find_element(By.CSS_SELECTOR, ".search_input").send_keys('세븐틴')


driver.find_element(By.CSS_SELECTOR, "[title = '검색어를 입력해 주세요.']").send_keys('트와이스')


driver.find_element(By.XPATH,'//*[@id="query"]').send_keys('BTS')





driver.find_element(By.LINK_TEXT, '쇼핑') # 해당 텍스트가 있는 링크 객체를 찾아줘


driver.find_element(By.LINK_TEXT, '쇼핑').click()


# 일부 매칭(일부 키워드만으로 이동하기)
driver.find_element(By.PARTIAL_LINK_TEXT, '증').click()


# 태그로 찾기
# 태그는 요소가 너무 많으므로 정확하게 대상을 찾을 때에는 권장 안함
driver.find_element(By.TAG_NAME,'div')


# 여러 개의 요소를 찾을 때
driver.find_elements(By.CSS_SELECTOR, '.link_service')


#태그 객체 안에 딕셔너리 속성이라 href 사용했었음
#지금은 리스트로 엮여있음!


driver.find_elements(By.CSS_SELECTOR, '.link_service')[0].get_attribute('href')


a = driver.find_elements(By.CSS_SELECTOR, '.link_service')
for i in a:
    print(i.get_attribute('href'))





# 테스트용 html
url = 'file:///C:/workspace/wassup3/02_Python_Collection/sample/signin.html'
driver = webdriver.Chrome(options = options)
driver.get(url)
time.sleep(2)


username = driver.find_element(By.NAME, 'username')
username.send_keys('korea')


password = driver.find_element(By.NAME, 'password')
password.send_keys('1234')


#클릭해서 로그인하기
login = driver.find_element(By.XPATH, '//*[@id="loginForm"]/input[3]')
login.click()








driver.back()


login = driver.find_element(By.XPATH, '/html/body/form/input[3]')
login.click()


driver.back()


login = driver.find_element(By.CSS_SELECTOR, '[value = Login]')
login.click()


driver.back()


username.clear()


password.clear()


username = driver.find_element(By.NAME, 'username')
username.send_keys('korea')
password = driver.find_element(By.NAME, 'password')
password.send_keys('1234')


username.submit()


driver.back()


driver.find_element(By.TAG_NAME,'p').text


#html 소스 추출하기
driver.page_source


driver.close()





24 .06.25 








from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time

options = Options()
options.add_argument("--headless=new") 
# options.add_argument('--window-size= x, y') #실행되는 브라우저 크기를 지정할 수 있습니다.
# options.add_argument('--start-maximized') #브라우저가 최대화된 상태로 실행됩니다.
# options.add_argument('--start-fullscreen') #브라우저가 풀스크린 모드(F11)로 실행됩니다.
# options.add_argument('--blink-settings=imagesEnabled=false') #브라우저에서 이미지 로딩을 하지 않습니다.
# options.add_argument('--mute-audio') #브라우저에 음소거 옵션을 적용합니다.
# options.add_argument('incognito') #시크릿 모드의 브라우저가 실행됩니다.
options.add_experimental_option("detach", True) #특정함수안에서  드라이버 생성시 함수종료될 때 브라우저 같이 종료되는 문제 대응


url = 'http://naver.com'
driver = webdriver.Chrome(options=options)
driver.get(url)
time.sleep(2)


print(driver.title)


driver.quit() # 탭 닫기


# close와 quit 차이 -> quit은 탭 닫기, close는 브라우저 전체 닫기(탭이 1개일 땐 탭 닫기 해도 브라우저 닫힘)





from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time

options = Options()
# options.add_argument("--start-maximized")
# options.add_argument("--headless=new") 
options.add_experimental_option("detach", True) #

url = 'http://naver.com'
driver = webdriver.Chrome(options=options)
driver.get(url)
time.sleep(2)


# 창의 너비/높이 구하기

size = driver.get_window_size()
width = size.get("width")
height = size.get("height")

print(str(width)+"px"+" "+str(height)+"px")


# 창 크기 조절
driver.set_window_size(800, 600)


# 스크린 상에서의 창 좌표
position = driver.get_window_position()
x = position.get('x')
y = position.get('y')

print("x : "+str(x)+" "+"y : "+str(y))
#사용하는 모니터, 소프트웨어, 메인보드에 따라 값이 다를 수 있음


driver.set_window_position(200,200)


# 창 크기 최대화
driver.maximize_window()


# 창 크기 최소화
driver.minimize_window()


# 전체 화면
driver.fullscreen_window()


# 스크린 샷
driver.save_screenshot('./image.png')


driver.close()





from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time, random, pandas as pd

options = Options()
options.add_argument('--window-size=974,1047')
options.add_argument('--window-position=-7,0')
options.add_experimental_option("detach", True)


# 웹드라이버 로드
driver = webdriver.Chrome( options = options)


# 조건 설정
where = 'blog'
query = '인공지능'
dateform = '20240101to20240625'
url = f'https://search.naver.com/search.naver?ssc=tab.{where}.all&query={query}&sm=tab_opt&nso=so%3Ar%2Cp%3Afrom{dateform}'
# url = f'https://search.naver.com/search.naver?where={where}&query={query}&sm=tab_op&nso=so:r,p:from{dateform}'
fname = f'{where}_{query}_{dateform}'


# url 접속
driver.get(url)
time.sleep(random.randint(2,3))





#네이버 뷰는 최대 1050까지만 노출
# 스크롤 10번
for i in range(10):
    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')
    time.sleep(random.randint(2, 3))


# get_view()
views = driver.find_elements(By.CSS_SELECTOR, '.lst_view .view_wrap')
result = []

for view in views:
    con_dict = {}
    con_dict['title'] = view.find_element(By.CSS_SELECTOR, '.title_link').text
    con_dict['text'] = view.find_element(By.CSS_SELECTOR, '.dsc_link').text
    con_dict['date'] = view.find_element(By.CSS_SELECTOR, '.sub').text
    result.append(con_dict)
    print(con_dict)
    
print('완료')


#저장된 게시물 리스트를 데이터프레임으로 변환후 csv로 저장
df = pd.DataFrame(result)
df


#데이터 프레임 저장
# csv는 sep 쉼표가 반드시 있어야 한글이 안깨짐
df.to_csv(f'output/naver_{fname}.csv', sep=',', encoding='utf-8-sig')





from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import time, random, pandas as pd

options = Options()
options.add_argument('--window-size=974,1047')
options.add_argument('--window-position=-7,0')
options.add_experimental_option("detach", True)

driver = webdriver.Chrome( options = options)
url = 'https://play.google.com/store/apps/details?id=com.estsoft.picnic'
driver.get(url)
time.sleep(random.randint(2,3))


# 스크롤
for i in range(10):
    review_box = driver.find_element(By.CSS_SELECTOR, 'div.fysCi')
    driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', review_box )
    time.sleep(random.randint(2, 3))


# 윈도우 팝업과 레이어 팝업은 구분해야함
# 아까 네이버는 윈도우 팝업
# 구글 플레이스토어는 독자 컴포넌트이기 때문에 그 요소를 찾아서 해당 요소에 대한 스크롤을 찾아야한다


reviews = driver.find_elements(By.CSS_SELECTOR, 'div.RHo1pe')
reviews





review_data = driver.find_elements(By.CSS_SELECTOR, 'div.RHo1pe')
result = []


for i in review_data:
    review = {}
    review['text'] = i.find_element(By.CSS_SELECTOR, '.h3YV2d').text
    review['star'] = len(i.find_elements(By.CSS_SELECTOR, 'span.Z1Dz7b'))
    review['date'] = i.find_element(By.CSS_SELECTOR, '.bp9Aid').text
    result.append(review)
    print(review)



df = pd.DataFrame(result)
df





from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import math, time

options = Options()
options.add_argument('--window-size=974,1047')
options.add_argument('--window-position=-7,0')
options.add_experimental_option("detach", True)


search = input('검색어를 입력하세요.')


URL = 'https://korean.visitkorea.or.kr/search/search_list.do?keyword='+search

driver = webdriver.Chrome(options=options)
driver.get(URL)
time.sleep(3)


driver.find_element(By.CSS_SELECTOR, "#s_recommend > .more_view > a").click()


# 단순히 moreview만 하면 그 위에 있는 여행정보 더보기가 더보기됨


contents = driver.find_elements(By.CSS_SELECTOR, '.tit')
contents


contents = driver.find_elements(By.CSS_SELECTOR, '.cont')
results = []

for i in contents:
    name = {}
    name['name'] = i.find_element(By.CSS_SELECTOR, '.tit').text
    name.append(name)
    print(name)


result = driver.find_elements(By.CSS_SELECTOR, '.tit a')
result[0].text


result = driver.find_elements(By.CSS_SELECTOR, '.tit a')
for i in range(len(result)):
    print(result[i].text)


#공백이 있는 이유 -> 동적 웹페이지: 여행정보, 축제 등등이 이 한 페이지 안에 동적으로 처리가 되어있어서
# 여행기사를 보고 조회하려고 헀지만 비어있는 페이지들은 여행정보에 대한 코드들(이벤트를 주지 않았기 때문에 값은 없음)


a = driver.find_element(By.XPATH, '//*[@id="search_result"]/ul/li[1]/div[1]/div[1]/a')
a.text
#잘 나오긴 한다!


a = driver.find_element(By.XPATH, '//*[@id="search_result"]/ul/li[2]/div[1]/div[1]/a')
a.text


a = '//*[@id="search_result"]/ul/li[*]/div[1]/div[1]/a'
result = driver.find_elements(By.XPATH,a)
len(a), result[0].text, result[1].text


for i, title in enumerate(result, 1):
    print(i,title.text)





driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/div[14]/a[2]').click()


cnt = int(input( '크롤링 할 건수는 몇건입니까?: '))
cnt


page_cnt = math.ceil(cnt/10)
print(page_cnt)





a = '//*[@id="search_result"]/ul/li[*]/div[1]/div[1]/a'
result = driver.find_elements(By.XPATH,a)
len(a), result[0].text, result[1].text


for i, title in enumerate(result, 1):
    print(i,title.text)





for i in page_cnt
    for j, title in enumerate(result, 1):
        print(j,title.txt)



페이지 수 먼저 카운트
input으로 페이지 수 받고, range 돌려서 +1(end index가 3이면 2번 페이지 까지 돌음)
mylist = 타이틀 수집 코드


tit_xpath = '//*[@id="search_result"]/ul/li[*]/div[1]/div[1]/a'
no = 0

for x in range(1, page_cnt+1): # 2번으로 가도 수집되자마자 다 뽑는게 아니라 15번까지 가면 break 걸림
    print(f'========= {x} 페이지 작업 =========')
    mylist = driver.find_elements(By.XPATH, tit_xpath) # 1페이지는 기본으로 보여줘서 굳이 먼저 안눌러도 되서 먼저 수집
    
    for item in mylist: # 10개를 뽑아서 한개씩 뽑기(2페이지 다 추출하는게 아니라 15개를 정확히 뽑음)
        no += 1  
        if no > cnt:
            break # 더이상 수집하지 않음
        print(no, item.text)
    
    if no <= cnt: # 아직 10번까지밖에 못했다면 2번 페이지로 넘어감
        a = f'/html/body/div[3]/div/div[1]/div[14]/a[{x+1}]' #x+1해서 다음 페이지 넘어감
        driver.find_element(By.XPATH, a).click()
#         next_button = driver.find_element(By.CSS_SELECTOR, f"a[id='{x+1}']")
#         driver.execute_script("arguments[0].click();", next_button)
        time.sleep(2)
    
print('========= 작업 완료 =========')
# driver.close()


6페이지를 넘어가는(더보기가 가능한) 페이지 순환 프로그램 만들기
지금코드는 5번 누르는 경우 6,7 페이지 등이 생기는 경우에 사용 가능 !
